{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dedsec05/dataset/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A63zApswNXm"
      },
      "source": [
        " ** A*  **\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KISl0OeWwLFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3879f905-c9bb-499f-ef06-0dce5651175d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acdeg 17\n"
          ]
        }
      ],
      "source": [
        "graph={\n",
        "    \"a\":[[\"b\",4],[\"c\",3]],  \n",
        "    \"b\":[[\"f\",5],[\"e\",12]],\n",
        "    \"c\":[[\"e\",10],[\"d\",7]],                                \n",
        "    \"f\":[[\"g\",16]],\n",
        "    \"e\":[[\"g\",5]],\n",
        "    \"d\":[[\"e\",2]],\n",
        "}\n",
        "h={\"a\":0,\"b\":12,\"c\":11,\"d\":6,\"e\":4,\"f\":11,\"g\":0}\n",
        "\n",
        "\n",
        "\n",
        "start=\"a\"\n",
        "end=\"g\"\n",
        "\n",
        "nodes=start\n",
        "path=[[start,h[start],0]] \n",
        "while nodes in graph:\n",
        "  temp=path.pop(0)\n",
        "  for j in graph[nodes]:\n",
        "    path.append([temp[0]+j[0],temp[1]+j[1],temp[1]+j[1]+h[j[0]]])\n",
        "  path.sort(key=lambda x:x[2])\n",
        "  nodes=path[0][0][-1]\n",
        "print(path[0][0],path[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr8oft26zgn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520d97d6-a7f6-4cb7-edbb-600dfc08cbc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acdeg 17\n"
          ]
        }
      ],
      "source": [
        "openl=[]\n",
        "closedl=[]\n",
        "start=\"a\"\n",
        "end=\"g\"\n",
        "openl=[['a',0,0]]\n",
        "res=[]\n",
        "while(len(openl)>0):\n",
        "  n=openl.pop(0)\n",
        "  if n[0] not in closedl and n[0][-1]!=end:\n",
        "    for v in graph[n[0][-1]]:\n",
        "      openl.append([n[0]+v[0],n[1]+v[1],n[2]+h[v[0]]])\n",
        "    closedl.append(n[0])\n",
        "    openl.sort(key=lambda x:x[-1])\n",
        "  else:\n",
        "    res.append(n)\n",
        "res.sort(key=lambda x:x[1])\n",
        "print(res[0][0],res[0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYyof0RL6agd"
      },
      "source": [
        "\n",
        "**find s** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FuxA-OnWMRzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6291da1-6676-4ae3-df62-7e8637e4b893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['japan' 'honda' 'blue' 1980 'economy']\n",
            "['japan' '?' 'blue' '?' 'economy']\n",
            "['japan' '?' 'blue' '?' 'economy']\n",
            "['japan' '?' '?' '?' 'economy']\n",
            "['japan' '?' '?' '?' 'economy']\n",
            "['japan' '?' '?' '?' 'economy']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"/content/sample_data/2nd.xlsx\")\n",
        "arr=df.to_numpy()\n",
        "output=arr[0]\n",
        "for i in range(1,len(arr)):      \n",
        "  if arr[i][-1]!='negative':\n",
        "    for j in range(len(output)-1):\n",
        "      if output[j]!=arr[i][j] and output[j]!='?':\n",
        "        \n",
        "        output[j]=\"?\"\n",
        "  print(output[:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD7GhoahNoN9"
      },
      "source": [
        "**candidate elimination**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "data=[]\n",
        "with open(\"/content/sample_data/car.csv\") as file:\n",
        "  for row in csv.reader(file,delimiter=\",\"):\n",
        "    data.append(row)\n",
        "col={}\n",
        "for i in range(len(data[0])):\n",
        "  col[i]=set()\n",
        "n=len(data[0])\n",
        "for i in range(1,len(data)):\n",
        "  col[0].add(data[i][0])\n",
        "  col[1].add(data[i][1])\n",
        "  col[2].add(data[i][2])\n",
        "  col[3].add(data[i][3])\n",
        "s=[None for i in range(n-1)]\n",
        "g=[(\"?\" * (n-1))]\n",
        "# print(\"?\"*4)\n",
        "\n",
        "def specific():\n",
        "  def match(coln):\n",
        "    flag=False\n",
        "    for i in range(n-1):\n",
        "      if s[i]!=\"?\" and  s[i]!=data[coln][i] and data[coln][-1]==\"Y\":\n",
        "        flag=True\n",
        "        break\n",
        "    if flag:\n",
        "      for i in range(n-1):\n",
        "        if s[i]!=data[coln][i]:\n",
        "          s[i]=data[coln][i] if s[i]==None else \"?\"\n",
        "\n",
        "  for i in range(len(data)):\n",
        "    print(s)\n",
        "    match(i)\n",
        "\n",
        "def match(gi,coln):\n",
        "  flag=False\n",
        "  for i in range(n-1):\n",
        "    if gi[i]!=\"?\" and  gi[i]!=data[coln][i] and data[coln][-1]==\"Y\":\n",
        "        flag=True\n",
        "        break\n",
        "  return flag\n",
        "\n",
        "def general():\n",
        "  for i in range(len(data)):\n",
        "    for col in g:\n",
        "      if match(col,i):\n",
        "        pass\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "specific()\n",
        "# general()\n",
        "print(s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s2ThP_m8iX7",
        "outputId": "a2bd5b84-1828-497e-dc26-72f329c4545d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "????\n",
            "[None, None, None, None, None]\n",
            "['japan', 'honda', 'blue', '1980', 'economy']\n",
            "['japan', 'honda', 'blue', '1980', 'economy']\n",
            "['japan', '?', 'blue', '?', 'economy']\n",
            "['japan', '?', 'blue', '?', 'economy']\n",
            "['japan', '?', '?', '?', 'economy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Navie**"
      ],
      "metadata": {
        "id": "oVuRVILYyHCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "msg=pd.read_csv('/content/sample_data/navie.csv',names=['message','label'])\n",
        "print('The dimensions of the dataset',msg.shape)\n",
        "msg['labelnum']=msg.label.map({'pos':1,'neg':0})\n",
        "X=msg.message\n",
        "y=msg.labelnum\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "#splitting the dataset into train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest=train_test_split(X,y)\n",
        "print(xtest.shape,xtrain.shape,ytest.shape,ytrain.shape)\n",
        "\n",
        "#output of count vectoriser is a sparse matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "xtrain_dtm = count_vect.fit_transform(xtrain)\n",
        "xtest_dtm=count_vect.transform(xtest)\n",
        "print(count_vect.get_feature_names())\n",
        "\n",
        "df=pd.DataFrame(xtrain_dtm.toarray(),columns=count_vect.get_feature_names())\n",
        "print(df)#tabular representation\n",
        "print(xtrain_dtm) #sparse matrix representation\n",
        "\n",
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(xtrain_dtm,ytrain)\n",
        "predicted = clf.predict(xtest_dtm)\n",
        "\n",
        "#printing accuracy metrics\n",
        "from sklearn import metrics\n",
        "print('Accuracy metrics')\n",
        "print('Accuracy of the classifer is',metrics.accuracy_score(ytest,predicted))\n",
        "print('Confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest,predicted))\n",
        "print('Recall and Precison ')\n",
        "print(metrics.recall_score(ytest,predicted))\n",
        "print(metrics.precision_score(ytest,predicted))"
      ],
      "metadata": {
        "id": "hcsFh1J8PZtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b042dff9-f442-495a-96a0-a6876fdd8756"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dimensions of the dataset (18, 2)\n",
            "0                      I love this sandwich\n",
            "1                  This is an amazing place\n",
            "2        I feel very good about these beers\n",
            "3                      This is my best work\n",
            "4                      What an awesome view\n",
            "5             I do not like this restaurant\n",
            "6                  I am tired of this stuff\n",
            "7                    I can't deal with this\n",
            "8                      He is my sworn enemy\n",
            "9                       My boss is horrible\n",
            "10                 This is an awesome place\n",
            "11    I do not like the taste of this juice\n",
            "12                          I love to dance\n",
            "13        I am sick and tired of this place\n",
            "14                     What a great holiday\n",
            "15           That is a bad locality to stay\n",
            "16           We will have good fun tomorrow\n",
            "17         I went to my enemy's house today\n",
            "Name: message, dtype: object\n",
            "0     1\n",
            "1     1\n",
            "2     1\n",
            "3     1\n",
            "4     1\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    1\n",
            "11    0\n",
            "12    1\n",
            "13    0\n",
            "14    1\n",
            "15    0\n",
            "16    1\n",
            "17    0\n",
            "Name: labelnum, dtype: int64\n",
            "(5,) (13,) (5,) (13,)\n",
            "['amazing', 'an', 'awesome', 'bad', 'best', 'boss', 'dance', 'do', 'enemy', 'great', 'he', 'holiday', 'horrible', 'house', 'is', 'juice', 'like', 'locality', 'love', 'my', 'not', 'of', 'place', 'restaurant', 'sandwich', 'stay', 'sworn', 'taste', 'that', 'the', 'this', 'to', 'today', 'view', 'went', 'what', 'work']\n",
            "    amazing  an  awesome  bad  best  boss  ...  to  today  view  went  what  work\n",
            "0         0   0        0    0     0     0  ...   1      0     0     0     0     0\n",
            "1         0   0        0    0     0     0  ...   0      0     0     0     0     0\n",
            "2         0   0        0    0     0     0  ...   0      0     0     0     0     0\n",
            "3         0   1        1    0     0     0  ...   0      0     1     0     1     0\n",
            "4         0   0        0    0     0     0  ...   0      0     0     0     1     0\n",
            "5         0   0        0    1     0     0  ...   1      0     0     0     0     0\n",
            "6         0   0        0    0     1     0  ...   0      0     0     0     0     1\n",
            "7         0   0        0    0     0     0  ...   0      0     0     0     0     0\n",
            "8         1   1        0    0     0     0  ...   0      0     0     0     0     0\n",
            "9         0   1        1    0     0     0  ...   0      0     0     0     0     0\n",
            "10        0   0        0    0     0     1  ...   0      0     0     0     0     0\n",
            "11        0   0        0    0     0     0  ...   1      1     0     1     0     0\n",
            "12        0   0        0    0     0     0  ...   0      0     0     0     0     0\n",
            "\n",
            "[13 rows x 37 columns]\n",
            "  (0, 18)\t1\n",
            "  (0, 31)\t1\n",
            "  (0, 6)\t1\n",
            "  (1, 7)\t1\n",
            "  (1, 20)\t1\n",
            "  (1, 16)\t1\n",
            "  (1, 30)\t1\n",
            "  (1, 23)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 20)\t1\n",
            "  (2, 16)\t1\n",
            "  (2, 30)\t1\n",
            "  (2, 29)\t1\n",
            "  (2, 27)\t1\n",
            "  (2, 21)\t1\n",
            "  (2, 15)\t1\n",
            "  (3, 35)\t1\n",
            "  (3, 1)\t1\n",
            "  (3, 2)\t1\n",
            "  (3, 33)\t1\n",
            "  (4, 35)\t1\n",
            "  (4, 9)\t1\n",
            "  (4, 11)\t1\n",
            "  (5, 31)\t1\n",
            "  (5, 28)\t1\n",
            "  :\t:\n",
            "  (7, 26)\t1\n",
            "  (7, 8)\t1\n",
            "  (8, 30)\t1\n",
            "  (8, 1)\t1\n",
            "  (8, 14)\t1\n",
            "  (8, 0)\t1\n",
            "  (8, 22)\t1\n",
            "  (9, 30)\t1\n",
            "  (9, 1)\t1\n",
            "  (9, 2)\t1\n",
            "  (9, 14)\t1\n",
            "  (9, 22)\t1\n",
            "  (10, 14)\t1\n",
            "  (10, 19)\t1\n",
            "  (10, 5)\t1\n",
            "  (10, 12)\t1\n",
            "  (11, 31)\t1\n",
            "  (11, 19)\t1\n",
            "  (11, 8)\t1\n",
            "  (11, 34)\t1\n",
            "  (11, 13)\t1\n",
            "  (11, 32)\t1\n",
            "  (12, 18)\t1\n",
            "  (12, 30)\t1\n",
            "  (12, 24)\t1\n",
            "Accuracy metrics\n",
            "Accuracy of the classifer is 0.4\n",
            "Confusion matrix\n",
            "[[0 3]\n",
            " [0 2]]\n",
            "Recall and Precison \n",
            "1.0\n",
            "0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**decision Tree**"
      ],
      "metadata": {
        "id": "a70ph0el2Ah7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, attribute):\n",
        "        self.attribute = attribute\n",
        "        self.children = []\n",
        "        self.answer = \"\"\n",
        "\n",
        "def subtables(data, col, delete):\n",
        "    dict = {}\n",
        "    items = np.unique(data[:, col])\n",
        "    count = np.zeros((items.shape[0], 1), dtype=np.int32)\n",
        "    for x in range(items.shape[0]):\n",
        "        for y in range(data.shape[0]):\n",
        "            if data[y, col] == items[x]:\n",
        "                count[x] += 1\n",
        "    for x in range(items.shape[0]):\n",
        "        dict[items[x]] = np.empty((int(count[x]), data.shape[1]), dtype=\"|S32\")\n",
        "        pos = 0\n",
        "        for y in range(data.shape[0]):\n",
        "            if data[y, col] == items[x]:\n",
        "                dict[items[x]][pos] = data[y]\n",
        "                pos += 1\n",
        "        if delete:\n",
        "            dict[items[x]] = np.delete(dict[items[x]], col, 1)\n",
        "    return items, dict\n",
        "\n",
        "def entropy(S):\n",
        "    items = np.unique(S)\n",
        "    if items.size == 1:\n",
        "        return 0\n",
        "    counts = np.zeros((items.shape[0], 1))\n",
        "    sums = 0\n",
        "    for x in range(items.shape[0]):\n",
        "        counts[x] = sum(S == items[x]) / (S.size * 1.0)\n",
        "    for count in counts:\n",
        "        sums += -1 * count * math.log(count, 2)\n",
        "    return sums\n",
        "\n",
        "def gain_ratio(data, col):\n",
        "    items, dict = subtables(data, col, delete=False)\n",
        "    total_size = data.shape[0]\n",
        "    entropies = np.zeros((items.shape[0], 1))\n",
        "    intrinsic = np.zeros((items.shape[0], 1))\n",
        "    for x in range(items.shape[0]):\n",
        "        ratio = dict[items[x]].shape[0]/(total_size * 1.0)\n",
        "        entropies[x] = ratio * entropy(dict[items[x]][:, -1])\n",
        "        intrinsic[x] = ratio * math.log(ratio, 2)\n",
        "    total_entropy = entropy(data[:, -1])\n",
        "    iv = -1 * sum(intrinsic)\n",
        "    for x in range(entropies.shape[0]):\n",
        "        total_entropy -= entropies[x]\n",
        "    return total_entropy / iv\n",
        "\n",
        "def create_node(data, metadata):\n",
        "    #print(np.unique(data[:,-1]))\n",
        "    if (np.unique(data[:, -1])).shape[0] == 1:\n",
        "        node = Node(\"\")\n",
        "        node.answer = np.unique(data[:, -1])[0]\n",
        "        return node\n",
        "    gains = np.zeros((data.shape[1] - 1, 1))\n",
        "    for col in range(data.shape[1] - 1):\n",
        "        gains[col] = gain_ratio(data, col)\n",
        "    split = np.argmax(gains)\n",
        "    node = Node(metadata[split])\n",
        "    metadata = np.delete(metadata, split, 0)\n",
        "    items, dict = subtables(data, split, delete=True)\n",
        "    for x in range(items.shape[0]):\n",
        "        child = create_node(dict[items[x]], metadata)\n",
        "        node.children.append((items[x], child))\n",
        "    return node\n",
        "\n",
        "def empty(size):\n",
        "    s = \"\"\n",
        "    for x in range(size-1):\n",
        "        s += \"   \"\n",
        "    return s+\"|--\"\n",
        "\n",
        "def print_tree(node, level):\n",
        "    if node.answer != \"\":\n",
        "        print(empty(level), node.answer)\n",
        "        return\n",
        "    print(empty(level), node.attribute)\n",
        "    for value, n in node.children:\n",
        "        print(empty(level + 1), value)\n",
        "        print_tree(n, level + 2)\n",
        "\n",
        "\n",
        "metadata = ['age','competition','type','profit']\n",
        "traindata = pd.read_csv(\"/content/sample_data/companu.csv\")\n",
        "data = np.array(traindata)\n",
        "node = create_node(data, metadata)\n",
        "print_tree(node, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGi_hCpS1B9J",
        "outputId": "87a5c412-5ebf-4284-b377-e57f11f561bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|-- age\n",
            "|-- mid\n",
            "   |-- competition\n",
            "      |-- b'no'\n",
            "         |-- b'up'\n",
            "      |-- b'yes'\n",
            "         |-- b'down'\n",
            "|-- new\n",
            "   |-- b'up'\n",
            "|-- old\n",
            "   |-- b'down'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN BackPROPOGATION**"
      ],
      "metadata": {
        "id": "NzqEk8Yv2prg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.array(([2, 9], [1, 5], [3, 6]))\n",
        "Y = np.array(([92], [86], [89]))\n",
        "X = X/np.amax(X,axis=0) # maximum of X array longitudinally\n",
        "Y = Y/100\n",
        "#Sigmoid Function\n",
        "def sigmoid (x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "#Derivative of Sigmoid Function\n",
        "def derivatives_sigmoid(x):\n",
        "    return x * (1 - x)\n",
        "#Variable initialization\n",
        "epoch=7000 #Setting training iterations\n",
        "lr=0.5 #Setting learning rate\n",
        "inputlayer_neurons = 2 #number of features in data set\n",
        "hiddenlayer_neurons = 3 #number of hidden layers neurons\n",
        "output_neurons = 1 #number of neurons at output layer\n",
        "#weight and bias initialization\n",
        "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
        "bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
        "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
        "bout=np.random.uniform(size=(1,output_neurons))\n",
        "#draws a random range of numbers uniformly of dim x*y\n",
        "\n",
        "for i in range(epoch):\n",
        "#Forward Propogation\n",
        "    hinp1=X.dot(wh)\n",
        "    hinp=hinp1 + bh\n",
        "    hlayer_act = sigmoid(hinp)\n",
        "\n",
        "    outinp1=hlayer_act.dot(wout)\n",
        "    outinp= outinp1+ bout\n",
        "    output = sigmoid(outinp)\n",
        "#Backpropagation\n",
        "    EO = Y-output\n",
        "    outgrad = derivatives_sigmoid(output)\n",
        "    d_output = EO* outgrad\n",
        "    \n",
        "    EH = d_output.dot(wout.T)\n",
        "    hiddengrad = derivatives_sigmoid(hlayer_act)#how much hidden layer wts contributed to error\n",
        "    d_hiddenlayer = EH * hiddengrad\n",
        "    \n",
        "    wout += hlayer_act.T.dot(d_output) *lr# dotproduct of nextlayererror and currentlayerop\n",
        "    \n",
        "    wh += X.T.dot(d_hiddenlayer) *lr\n",
        "\n",
        "print(\"Input: \\n\" + str(X)) \n",
        "print(\"Actual Output: \\n\" + str(Y))\n",
        "print(\"Predicted Output: \\n\" ,output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWEq3gGO3IeT",
        "outputId": "fbddab08-4858-42bb-ef53-6dab8f92a8f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            " [[0.89672214]\n",
            " [0.87936761]\n",
            " [0.89336232]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J_F2uKNs3Lnt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}